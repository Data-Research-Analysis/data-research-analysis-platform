# =============================================================================
# Data Research Analysis Platform - Backend Environment Configuration
# =============================================================================
# This file contains environment variables for the backend Node.js/Express server.
#
# SETUP INSTRUCTIONS:
# 1. Copy this file to .env: cp .env.example .env
# 2. Fill in the required values marked with [REQUIRED]
# 3. Configure external services (reCAPTCHA, AWS, email, etc.)
# 4. Set up database connections
# 5. Start the backend: npm run dev
#
# SECURITY WARNING: Never commit the actual .env file to version control!
# Contains sensitive credentials and API keys.
# =============================================================================

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------

# [REQUIRED] The port on which the backend server will run
PORT=3002

# [REQUIRED] Public URL for the backend API (used for CORS and webhooks)
PUBLIC_BACKEND_URL=http://localhost:3002

# Environment mode: development, staging, production
NODE_ENV=development

# -----------------------------------------------------------------------------
# Authentication & Security
# -----------------------------------------------------------------------------

# [REQUIRED] The secret key for reCAPTCHA verification
# Get from: https://www.google.com/recaptcha/admin
RECAPTCHA_SECRET=your_recaptcha_secret_key_here

# [REQUIRED] The secret key used for signing JWT tokens (minimum 32 characters)
# Generate with: openssl rand -base64 32
JWT_SECRET=your_jwt_secret_key_here_minimum_32_characters

# Password hashing salt rounds (10-12 recommended for production)
PASSWORD_SALT=10

# [REQUIRED] Encryption key for sensitive data (connection details, credentials)
# MUST be 64 hexadecimal characters (32 bytes for AES-256)
# Generate with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
# WARNING: Keep this key secure! Loss of this key means loss of encrypted data.
ENCRYPTION_KEY=your_64_character_hex_encryption_key_here_replace_this_with_generated_key

# -----------------------------------------------------------------------------
# Rate Limiting Configuration
# -----------------------------------------------------------------------------

# Enable/disable rate limiting (set to 'false' to disable in development)
# Default: true (always enabled in production)
RATE_LIMIT_ENABLED=true

# Authentication endpoints rate limits (login, register, password reset)
# Protects against brute force attacks
# Default: 5 requests per 15 minutes per IP
RATE_LIMIT_AUTH_WINDOW_MS=900000
RATE_LIMIT_AUTH_MAX=5

# Expensive operations rate limits (file uploads, sync, AI operations)
# Default: 10 requests per minute per user/IP
RATE_LIMIT_EXPENSIVE_WINDOW_MS=60000
RATE_LIMIT_EXPENSIVE_MAX=10

# General API rate limits (all other endpoints)
# Default: 100 requests per minute per user/IP
RATE_LIMIT_API_WINDOW_MS=60000
RATE_LIMIT_API_MAX=100

# AI operations rate limits (computationally expensive)
# Default: 5 requests per minute per user
RATE_LIMIT_AI_WINDOW_MS=60000
RATE_LIMIT_AI_MAX=5

# OAuth callback rate limits
# Default: 10 requests per 5 minutes per IP
RATE_LIMIT_OAUTH_WINDOW_MS=300000
RATE_LIMIT_OAUTH_MAX=10

# Enable/disable encryption for connection details (true by default, set to false to disable)
ENCRYPTION_ENABLED=true

# -----------------------------------------------------------------------------
# Primary Database Configuration (PostgreSQL)
# -----------------------------------------------------------------------------

# Database driver type (currently supports: postgres)
DB_DRIVER=postgres

# [REQUIRED] PostgreSQL host for migrations (usually localhost for development)
POSTGRESQL_HOST_MIGRATIONS=localhost

# [REQUIRED] PostgreSQL host for runtime (docker service name or IP)
POSTGRESQL_HOST=database.dataresearchanalysis.test

# [REQUIRED] PostgreSQL port for migrations
POSTGRESQL_PORT_MIGRATIONS=5434

# [REQUIRED] PostgreSQL port for runtime
POSTGRESQL_PORT=5432

# [REQUIRED] PostgreSQL database username
POSTGRESQL_USERNAME=dra_user

# [REQUIRED] PostgreSQL database password
POSTGRESQL_PASSWORD=your_postgres_password_here

# [REQUIRED] PostgreSQL database name
POSTGRESQL_DB_NAME=dra_database

# -----------------------------------------------------------------------------
# External Database Connections (Optional - for data sources)
# -----------------------------------------------------------------------------

# MySQL database configuration for external data source connections
MYSQLDB_USER=mysql_user
MYSQLDB_ROOT_PASSWORD=your_mysql_password_here
MYSQLDB_DATABASE=mysql_database
MYSQLDB_LOCAL_PORT=3306
MYSQLDB_DOCKER_PORT=3306

# MariaDB database configuration for external data source connections
MARIADB_USER=mariadb_user
MARIADB_ROOT_PASSWORD=your_mariadb_password_here
MARIADB_DATABASE=mariadb_database
MARIADB_LOCAL_PORT=3307
MARIADB_DOCKER_PORT=3306

# -----------------------------------------------------------------------------
# Email Service Configuration
# -----------------------------------------------------------------------------

# Email service driver (mailtrap, sendgrid, ses, smtp)
MAIL_DRIVER=mailtrap

# [REQUIRED] Email service host
MAIL_HOST=sandbox.smtp.mailtrap.io

# [REQUIRED] Email service port
MAIL_PORT=2525

# [REQUIRED] Email service username/API key
MAIL_USER=your_email_username_here

# [REQUIRED] Email service password/API secret
MAIL_PASS=your_email_password_here

# [REQUIRED] From email address for outgoing emails
MAIL_FROM=noreply@dataresearchanalysis.com

# [REQUIRED] Reply-to email address
MAIL_REPLY_TO=support@dataresearchanalysis.com

# -----------------------------------------------------------------------------
# Redis Configuration
# -----------------------------------------------------------------------------

# Redis host (localhost for development, service name for docker)
REDIS_HOST=localhost

# Redis port
REDIS_PORT=6379

# Data driver for caching and sessions (redis recommended)
DATA_DRIVER=redis

# -----------------------------------------------------------------------------
# Socket.IO Real-time Communication
# -----------------------------------------------------------------------------

# Backend Socket.IO server URL (where backend runs)
SOCKETIO_SERVER_URL=http://localhost

# Backend Socket.IO server port (same as PORT usually)
SOCKETIO_SERVER_PORT=3002

# [REQUIRED] Frontend URL for CORS policy
SOCKETIO_CLIENT_URL=http://localhost

# [REQUIRED] Frontend port for CORS policy
SOCKETIO_CLIENT_PORT=3000

# -----------------------------------------------------------------------------
# AWS Services Configuration (Optional)
# -----------------------------------------------------------------------------

# AWS Access Key ID for S3, Textract, and other AWS services
# Get from: AWS IAM Console
AWS_ACCESS_KEY_ID=your_aws_access_key_id_here

# AWS Secret Access Key
AWS_SECRET_ACCESS_KEY=your_aws_secret_access_key_here

# AWS region for services (e.g., us-east-1, eu-west-1)
AWS_S3_REGION=us-east-1

# S3 bucket name for image extraction and file storage
AWS_S3_IMAGES_EXTRACT_BUCKET=your-s3-bucket-name-here

# -----------------------------------------------------------------------------
# Background Job Processing
# -----------------------------------------------------------------------------

# Interval for checking queue status (milliseconds)
QUEUE_STATUS_INTERVAL=5000

# Number of worker processes for background jobs
NUM_WORKERS=3

# -----------------------------------------------------------------------------
# Image Processing Configuration
# -----------------------------------------------------------------------------

# Default image page width for PDF processing (pixels)
IMAGE_PAGE_WIDTH=4000

# Default image page height for PDF processing (pixels)
IMAGE_PAGE_HEIGHT=6000

# -----------------------------------------------------------------------------
# AI Services Configuration
# -----------------------------------------------------------------------------

# [REQUIRED] Google Gemini API Key for AI Data Modeler
# The AI Data Modeler uses Google Gemini AI to generate intelligent data model templates
# Get your API key from: https://aistudio.google.com/app/apikey
# Required for: AI-powered data model generation with preset templates
GEMINI_API_KEY=your_gemini_api_key_here

# -----------------------------------------------------------------------------
# Google OAuth Configuration (For Google Analytics Integration)
# -----------------------------------------------------------------------------

# [REQUIRED for Google Analytics] Google OAuth 2.0 Client ID
# Get from: https://console.cloud.google.com/apis/credentials
# Create OAuth 2.0 Client ID with type "Web application"
# Required for: Google Analytics data source connector
GOOGLE_CLIENT_ID=your_google_client_id_here.apps.googleusercontent.com

# [REQUIRED for Google Analytics] Google OAuth 2.0 Client Secret
GOOGLE_CLIENT_SECRET=your_google_client_secret_here

# Google OAuth redirect URI (automatically uses PUBLIC_BACKEND_URL if not set)
# Default: ${PUBLIC_BACKEND_URL}/api/oauth/google/callback
# Add this exact URL to "Authorized redirect URIs" in Google Cloud Console
# GOOGLE_REDIRECT_URI=http://localhost:3002/api/oauth/google/callback

# -----------------------------------------------------------------------------
# Google Ads API Configuration (For Google Ads Integration)
# -----------------------------------------------------------------------------

# [REQUIRED for Google Ads] Google Ads Developer Token
# This is a separate credential required for Google Ads API access
# Get from: https://ads.google.com/aw/apicenter
# 
# For Testing (Instant Approval):
#   1. Go to https://ads.google.com/aw/apicenter
#   2. Click "Get a developer token"
#   3. Select "I will use the API for test purposes only"
#   4. Token will be issued immediately with test account access
#
# For Production (24-48 hour approval):
#   1. Apply for Basic or Standard access level
#   2. Explain your use case (data analysis platform)
#   3. Wait for Google approval
#   4. Token will be upgraded to production level
#
# Note: This is separate from OAuth Client ID/Secret
# You need BOTH OAuth credentials AND the developer token
GOOGLE_ADS_DEVELOPER_TOKEN=your_google_ads_developer_token_here

# -----------------------------------------------------------------------------
# Scheduled Backup Configuration
# -----------------------------------------------------------------------------

# Cron expression for scheduled backups (default: daily at midnight)
# Format: minute hour day-of-month month day-of-week
# Examples:
#   0 0 * * *    = Daily at midnight
#   0 2 * * *    = Daily at 2 AM
#   0 */6 * * *  = Every 6 hours
#   0 0 * * 0    = Weekly on Sunday at midnight
#   0 0 1 * *    = Monthly on the 1st at midnight
BACKUP_SCHEDULE=0 0 * * *

# Enable/disable scheduled backups (true/false)
BACKUP_ENABLED=true

# Number of days to retain backup files before automatic cleanup
BACKUP_RETENTION_DAYS=30

# System user ID for scheduled backups (typically admin user ID)
BACKUP_SYSTEM_USER_ID=1

# Maximum backup file size in MB
BACKUP_MAX_SIZE_MB=500

# Enable automatic cleanup of old backups (true/false)
BACKUP_AUTO_CLEANUP=true

# Backup storage path (relative to backend directory)
BACKUP_STORAGE_PATH=./backend/private/backups
